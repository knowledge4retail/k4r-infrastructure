# K4R Logging Infrastructure

## Introduction

When running a K4R on premise, you need to configure the logging infrastructure to be able to collect and view the log events that are generated by the different K4R applications.

This setup can be well run in the cloud, however, while running on the cloud, you can alternatively easily use the supported logging services from the cloud e.g. azure log analytics. You do not need in this case any extra configuration.

This setup uses the EFK Stack for logging. (Elasticsearch, Fluentd, Kibana)
[Elasticsearch](https://www.elastic.co/guide/en/elasticsearch/reference/index.html) v7.16 is used for storing the logs.
[Fluentd](https://www.fluentd.org/) is used for processing and collecting the logs from the running containers.
[Kibana](https://www.elastic.co/guide/en/kibana/current/index.html) is used for viewing and searching the logs.

## Requirements

* access to a running kubernetes cluster
* docker, kubectl `>= v1.20.0` and helm `>= v3.6.3`   installed on your local machine
* the current `kubectl` context is pointing to the correct Kubernetes cluster
* the current namespace is set to the required namespace for the logging infrastructure
* the following instructions assume that you are running the commands on bash (or a similar shell)

## Setup

This setup is done by the following steps:

* Create Elasticsearch cluster

* Create Fluentd DaemonSets to push logs to the Elasticsearch cluster

* Create Kibana to fetch and display logs stored in the Elasticsearch cluster

### Create Elasticsearch cluster

These instructions are based on the [Elasticsearch documentation](https://www.elastic.co/guide/en/elasticsearch/reference/7.16/index.html) and the security example from the elastic helm-charts repository on GitHub [elastic v7.16](https://github.com/elastic/helm-charts/tree/7.16/elasticsearch/examples/security)

1. from within the directory `k4r-infrastructure/logging-infrastructure` run `make secrets`

2. you shall be able to see in your cluster the following resources:
   1. `elastic-certificates` secret
   2. `elastic-certificates-pem` secret
   3. `elastic-certificates-crt` secret
   4. `elastic-credentials` secret
3. run `helm repo add elastic https://helm.elastic.co` and then `helm repo update`
4. run the command: `helm install elasticsearch-logging elastic/elasticsearch -f elasticsearch.values.yml --version 7.16.2 --wait --debug --atomic`


### Create Fluentd DaemonSets

The fluentd DaemonSets will be running by default in the `kube-system` namespace. unless you have changed the namespace in the `fluentd.yaml` file.

1. run `export K8S_NAMESPACE=$(kubectl config view --minify --output 'jsonpath={..namespace}'; echo)`

2. run  `export FLUENT_ELASTICSEARCH_PASSWORD=$(kubectl get secrets/elastic-credentials --template={{.data.password}} | base64 -d)`.

3. run `envsubst < efk-logging-template/fluentd.yml | kubectl apply -f -`

### Create Kibana

1. to install Kibana you need to create a secret using the make command: `make kibanasecret`
2. in `kibana.valus.yaml` change the `KIBANA_ELASTICSEARCH_HOST` to the qualified hostname of the Elasticsearch cluster e.g. `elasticsearch-logging.my-namespace.svc.cluster.local` where `my-namespace` is the namespace in which the Elasticsearch cluster is running.
3. Run the following command:
   `helm install kibana-logging elastic/kibana -f kibana.values.yml --version 7.16.2 --wait --debug --atomic`

#### Accessing the Kibana UI using port-forwarding

1. To connect to the Kibana UI run the following command: `kubectl port-forward svc/kibana-logging-kibana 5601:5601`

2. in browser, navigate to: `https://localhost:5601`

3. enter the username and password from the `elastic-credentials` secret.

Alternatively Kibana can be accessed by configuring the Ingress resource in Kibana chart.
See the official [Values.yaml](https://github.com/elastic/helm-charts/blob/7.16/kibana/values.yaml#L135)
